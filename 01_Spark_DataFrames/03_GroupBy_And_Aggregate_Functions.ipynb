{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Imports\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import (StructField,StringType, \n",
    "                               IntegerType,StructType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Python imports.\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the seed for the Random Number Generator.\n",
    "random.seed(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Spark session.\n",
    "spark = SparkSession.builder.appName('aggs').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can infer the schema/types (only in CSV), and header tells us\n",
    "# that the first row are the names of the columns.\n",
    "df = spark.read.csv('Data/sales_info.csv',\n",
    "                    inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows we read.\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See what schema was inferred (together with column names from row).\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a GroupedData object. You can't call directly on it\n",
    "# show but now you can call many aggregation functions.\n",
    "grouped = df.groupBy(\"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can call several functions on grouped data, but mathematical ones\n",
    "# will only work on numerical columns. You can't call .show() directly\n",
    "# on data that has been grouped, you have to run an aggregate function.\n",
    "grouped.mean().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Company|count|\n",
      "+-------+-----+\n",
      "|   APPL|    4|\n",
      "|   GOOG|    3|\n",
      "|     FB|    2|\n",
      "|   MSFT|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For grouped data you can call max, min, count, mean, avg, etc.\n",
    "grouped.count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A User-Defined Function. To be called in DataFrame operations,\n",
    "# receiving the values from each Column and returning a Column type.\n",
    "random_udf = f.udf(lambda value: random.randint(0, value), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In each row lets put an extra column where the value is a random\n",
    "# integer value between 0 and the value of the 'Sales' column.\n",
    "new_grouped = (df.withColumn('Random', random_udf(f.col('Sales')))\n",
    "                .groupBy(\"Company\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+------+\n",
      "|Company| Person|Sales|Twelve|\n",
      "+-------+-------+-----+------+\n",
      "|   GOOG|    Sam|200.0|    12|\n",
      "|   GOOG|Charlie|120.0|    12|\n",
      "|   GOOG|  Frank|340.0|    12|\n",
      "|   MSFT|   Tina|600.0|    12|\n",
      "|   MSFT|    Amy|124.0|    12|\n",
      "|   MSFT|Vanessa|243.0|    12|\n",
      "|     FB|   Carl|870.0|    12|\n",
      "|     FB|  Sarah|350.0|    12|\n",
      "|   APPL|   John|250.0|    12|\n",
      "|   APPL|  Linda|130.0|    12|\n",
      "|   APPL|   Mike|750.0|    12|\n",
      "|   APPL|  Chris|350.0|    12|\n",
      "+-------+-------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you don't want to compute something based on a column but instead\n",
    "# fixed or column independent data, use the literal function.\n",
    "(df.withColumn('Twelve', f.lit(12))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+\n",
      "|Company|sum(Sales)|       avg(Random)|\n",
      "+-------+----------+------------------+\n",
      "|   APPL|    1480.0|             207.0|\n",
      "|   GOOG|     660.0| 84.33333333333333|\n",
      "|     FB|    1220.0|             510.0|\n",
      "|   MSFT|     967.0|231.33333333333334|\n",
      "+-------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple aggregator functions can be applied in a single call on\n",
    "# different numerical columns!\n",
    "new_grouped.agg({'Sales' : 'sum', 'Random' : 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe has to be persisted 'cache()' because otherwise\n",
    "# everytime we'll perform some computation on it, it will retrieve\n",
    "# the columns and the 'random' column will be re-rolled.\n",
    "rnd_sales = df.withColumn('Random', random_udf(f.col('Sales'))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+------+\n",
      "|Company| Person|Sales|Random|\n",
      "+-------+-------+-----+------+\n",
      "|   GOOG|    Sam|200.0|    51|\n",
      "|   GOOG|Charlie|120.0|    32|\n",
      "|   GOOG|  Frank|340.0|    92|\n",
      "|   MSFT|   Tina|600.0|   118|\n",
      "|   MSFT|    Amy|124.0|    98|\n",
      "|   MSFT|Vanessa|243.0|   148|\n",
      "|     FB|   Carl|870.0|   664|\n",
      "|     FB|  Sarah|350.0|   277|\n",
      "|   APPL|   John|250.0|   202|\n",
      "|   APPL|  Linda|130.0|    40|\n",
      "|   APPL|   Mike|750.0|   363|\n",
      "|   APPL|  Chris|350.0|   229|\n",
      "+-------+-------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since data is cache'd, the random column won't be recomputed.\n",
    "# Remember that a DataFrame is just a set of operations, only\n",
    "# certain actions causes the whole thing to be computed.\n",
    "rnd_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT Sales)|\n",
      "+---------------------+\n",
      "|                   11|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also make use of other really nice Spark functions.\n",
    "# In the select you can pass some of the predefined functions,\n",
    "# which there's PLENTY of in the pyspark.sql.functions module.\n",
    "df.select(f.countDistinct('Sales')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   ST2|\n",
      "+------+\n",
      "|250.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can alias columns to different names for clarity!\n",
    "# `stddev_samp` is an ugly name. But you still have a\n",
    "# hard to read number with a bunch of significant digits.\n",
    "sales_std = df.select(f.stddev('Sales').alias('STDDEV'))\n",
    "# format a column to two significant digits!\n",
    "sales_std = sales_std.select(f.format_number('STDDEV', 2).alias('ST2'))\n",
    "sales_std.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can order by one (or multiple) keys, the first keys take precedence\n",
    "# and then in case of a tie it takes into account the following keys and\n",
    "# so on. By default it will sort ascending and receiving only the column\n",
    "# name(s), you have to manually specify the column object and .desc() if\n",
    "# you want to use descending.\n",
    "df.orderBy('Company', f.col('Sales').desc(), df['Person'].asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
